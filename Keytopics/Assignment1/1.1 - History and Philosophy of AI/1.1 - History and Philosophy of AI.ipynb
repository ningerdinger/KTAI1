{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a16008d8-6dfd-4b19-8317-6099092bcdd2",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "* There will be questions embedded in the notebook and a cell for you to provide your answer (denoted with A:). Answer all the markdown/text cells with **\"A: \"** on them. \n",
    "* You may not reproduce this notebook or share them to anyone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab18139-11f6-45c0-bac7-dcfbcb4fafdf",
   "metadata": {},
   "source": [
    "Place your answers to the questions directly inline on the same cell as **A:**\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab5accf-0c81-4b44-afdc-e31819594af9",
   "metadata": {},
   "source": [
    "<span style='color:red'>**Question 00:**</span> What is your favorite ice cream flavor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6190b942-f1fe-49fa-acc5-e7ce3f7563c7",
   "metadata": {},
   "source": [
    "<span style='color:red'>**A00:**</span> My favorite flavor ice cream flavor is pistachio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4882c80d-aa34-40db-aa4d-7552df1975a5",
   "metadata": {},
   "source": [
    "# Assignment 1.1 - History and Philosophy Notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc50ae6-15a0-4f54-9977-ad1f7c54ca65",
   "metadata": {},
   "source": [
    "<span style='color:red'>**Question 01:**</span> With the emergence of large languange models (LLMs), many have claimed that the turing test has been beaten. Is this evidence that the LLMs are intelligent? Why or why not? Substantiate your answers / claims with either your own experiments, or evidence from articles you found online. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec570bfa-917d-401c-8b7e-5f5f6e13b3e2",
   "metadata": {},
   "source": [
    "<span style='color:red'>**A01:**</span> \n",
    "he Turing test, as defined on the internet, is about testing a computer's intelligence by seeing if a human can tell it apart from another human based on its responses to questions. The buzz around the Turing test being beaten comes from the impressive progress in generative AI recently, like large language models (LLMs) and computer vision. While I think there's some truth to this claim, it's important to remember these models sometimes give blatantly wrong answers that any observant human would spot.\n",
    "\n",
    "![alt text](Example.jpg \"Test\")\n",
    "\n",
    "Take this example: when I was asked how many \"i\"s are in \"inconspicuous,\" I gave the correct answer at first. But when I was told my answer was wrong, I ended up giving an incorrect response, even though any human using a bit of critical thinking could see my original answer was right. This shows that while generative AI and LLMs can mimic human intelligence pretty well, they don't actually understand what they're sayingâ€”they just predict responses based on patterns they've learned.\n",
    "\n",
    "![alt text](math.jpg \"Test\")\n",
    "\n",
    "In another example found online, someone asked the AI to do a simple math calculation, and it couldn't get it right. A high school student would have no problem with the same calculation. This again highlights how LLMs can mimic intelligence without truly understanding or thinking critically. Daniel mentioned in a lecture that this is why they use an API for simple math instead of letting AI handle it.\n",
    "\n",
    "\n",
    "These examples underscore the fact that while AI can be very convincing, it isn't truly intelligent and lacks the depth of understanding that humans have."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3fa394-d241-4e3d-9b7c-ed7572143e84",
   "metadata": {},
   "source": [
    "<span style='color:red'>**Question 02:**</span> There's an article written by Dziri et al. entitled \"Faith and Fate: Limits of Transformers on Compositionality\". This paper shows some insights on how LLMs built using transformers operate. Summarize their key findings and relate them to the philosophies (discussed in Learning Unit 1) that this paper provide the most evidence to? Justify your answers. \n",
    "\n",
    "Link to paper: https://arxiv.org/abs/2305.18654"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2e43ad-f78f-4adf-a24c-7ca640dfb536",
   "metadata": {},
   "source": [
    "<span style='color:red'>**A02:**</span> The study investigates the limitations of large language models (LLMs) like GPT-3, GPT-3.5, and GPT-4 in handling complex, multi-step reasoning tasks. As tasks become more complex, model performance deteriorates significantly, both in problem size and average parallelism. The study finds that models predict partially correct answers due to task distribution particularities, allowing for guessing without full reasoning. Finetuning with question-answer and question-scratchpad pairs yields high accuracy for in-distribution examples but poor generalization for out-of-domain (OOD) cases. Error analysis shows models perform well in single-step reasoning but struggle with multi-step reasoning, relying on pattern matching rather than true algorithmic understanding. Theoretical insights suggest transformers' performance declines exponentially with increasing problem size due to compounding stochastic errors, indicating they are not well-suited for compositional tasks. Extended training does not improve generalization, and tasks heavily reliant on specific input features create an illusion of compositional reasoning. These findings highlight the need for future research to address transformers' limitations in solving complex, multi-step tasks and suggest that current transformer models are not well-suited for handling compositional reasoning.\n",
    "\n",
    "This study underscores the inherent limitations of AI in generalizing from training data to more intricate and unfamiliar problems, maintaining accuracy over extended reasoning processes, and addressing compounded errors in multi-step tasks. It also emphasizes the importance of not relying solely on AI for everything. While AI can assist with many tasks and provide valuable insights, it lacks the depth of human understanding, creativity, and emotional intelligence. Over-reliance on AI can lead to biased results, loss of critical thinking skills, and ethical dilemmas. Therefore, human oversight is essential to ensure accuracy, fairness, and ethical decision-making, using AI as a tool to augment human capabilities rather than replace them. This balanced approach is crucial for responsibly integrating AI into various aspects of life."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fbc92c-66e1-4243-afff-b3e7bf893b27",
   "metadata": {},
   "source": [
    "<span style='color:red'>**Question 03:**</span> Imagine a time in the future where a large language model can correctly answer all questions from a large set of comprehensive benchmarks on various domains and even surpass humans in all the benchmarks. Does it still matter if the LLMs are intelligent or not? Why or why not? Explain your answers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a36987-b40f-4c0d-8982-55a21742a864",
   "metadata": {},
   "source": [
    "<span style='color:red'>**A03:**</span> It really depends on the situation. If we're just talking about efficiency and practical uses for Gen AI, then whether they're truly intelligent might not matter much. But when it comes to emotional understanding, empathy, creativity, and building relationships, it's a different story. Even if LLMs beat humans in every test, they can't fully replace the human touch and the ability to connect with others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784426cc-f6a4-4be8-b7fa-3512c7859ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f54a398e-eea9-4f7c-a334-68b3ccc9c1a6",
   "metadata": {},
   "source": [
    "<span style='color:red'>**Question:**</span> How much time did it take you to answer this notebook?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e57af0e-3605-49f8-8130-1045cd87c7e3",
   "metadata": {},
   "source": [
    "<span style='color:red'>**A:**</span> About a hour or two since I wanted to carefully review existing literature in order to properly answer your questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbaf0e8-d285-4e44-aa5e-aab3a27409a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
